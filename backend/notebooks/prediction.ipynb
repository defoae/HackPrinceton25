{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47831ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import models\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f77f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    return tf.keras.models.load_model('ai_detector_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25224ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dimashmadiyar/Documents/GitHub/HackPrinceton25/backend/video_frames clip_prob= 0.7444841861724854 clip_label= 1 n_frames= 420\n",
      "We are 74 % sure video is AI-generated based on 420 frames analyzed\n"
     ]
    }
   ],
   "source": [
    "def load_frames_from_dir(dir_path, target_size=(150,150), ext=('.jpg','.jpeg','.png')):\n",
    "    files = sorted([f for f in os.listdir(dir_path) if f.lower().endswith(ext)])\n",
    "    if not files:\n",
    "        raise ValueError(f\"No image files found in {dir_path}\")\n",
    "    frames = []\n",
    "    for fname in files:\n",
    "        fpath = os.path.join(dir_path, fname)\n",
    "        img = Image.open(fpath).convert('RGB').resize(target_size)\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        frames.append(arr)\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "\n",
    "def predict_frames_and_clip(dir_path, model=None, threshold=0.5, target_size=(150,150)):\n",
    "    if model is None:\n",
    "        model = load_model()\n",
    "    frames = load_frames_from_dir(dir_path, target_size=target_size)\n",
    "    preds = model.predict(frames, verbose=0)\n",
    "    preds = np.asarray(preds).reshape(-1) \n",
    "    labels = (preds > threshold).astype(int)\n",
    "    clip_prob = float(preds.mean())\n",
    "    clip_label = int(clip_prob > threshold)\n",
    "    return {\n",
    "        'frame_probs': preds,\n",
    "        'frame_labels': labels,\n",
    "        'clip_prob': clip_prob,\n",
    "        'clip_label': clip_label,\n",
    "        'n_frames': len(preds)\n",
    "    }\n",
    "\n",
    "\n",
    "def predict_on_clips(dir_list, model=None, threshold=0.5, target_size=(150,150)):\n",
    "    \"\"\"Run predict_frames_and_clip for a list of directories and return results.\n",
    "\n",
    "    dir_list: iterable of directory paths (each directory contains ordered frames for one clip)\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = load_model()\n",
    "    results = {}\n",
    "    for d in dir_list:\n",
    "        results[d] = predict_frames_and_clip(d, model=model, threshold=threshold, target_size=target_size)\n",
    "    return results\n",
    "\n",
    "clip_dirs = ['/Users/dimashmadiyar/Documents/GitHub/HackPrinceton25/backend/video_frames']\n",
    "results = predict_on_clips(clip_dirs)\n",
    "for clip, r in results.items():\n",
    "    print(clip, 'clip_prob=', r['clip_prob'], 'clip_label=', r['clip_label'], 'n_frames=', r['n_frames'])\n",
    "    print(\"We are\", (int((r['clip_prob']) * 100)),\"%\",\"sure video is AI-generated based on\", r['n_frames'], \"frames analyzed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
